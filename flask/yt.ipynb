{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/naitik/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/naitik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/naitik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/naitik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def text_processing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.151.58:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "@app.route('/api/v1/youtube-comments', methods=['POST'])\n",
    "def process_comments():\n",
    "    data = request.json\n",
    "    comments = data.get(\"comments\", [])\n",
    "\n",
    "    if not comments:\n",
    "        return jsonify({'error': 'No comments provided'}), 400\n",
    "\n",
    "    df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
    "    df = df.dropna(subset=[\"Comment\"])\n",
    "\n",
    "\n",
    "    df[\"Positive\"] = df[\"Comment\"].apply(lambda x: sentiments.polarity_scores(str(x))[\"pos\"])\n",
    "    df[\"Negative\"] = df[\"Comment\"].apply(lambda x: sentiments.polarity_scores(str(x))[\"neg\"])\n",
    "    df[\"Neutral\"] = df[\"Comment\"].apply(lambda x: sentiments.polarity_scores(str(x))[\"neu\"])\n",
    "    df['Compound'] = df[\"Comment\"].apply(lambda x: sentiments.polarity_scores(str(x))[\"compound\"])\n",
    "\n",
    "    sentiment = []\n",
    "    for score in df[\"Compound\"]:\n",
    "        if score >= 0.05:\n",
    "            sentiment.append('Positive')\n",
    "        elif score <= -0.05:\n",
    "            sentiment.append('Negative')\n",
    "        else:\n",
    "            sentiment.append('Neutral')\n",
    "\n",
    "    df[\"Sentiment\"] = sentiment\n",
    "    df = df.drop(['Positive', 'Negative', 'Neutral', 'Compound'], axis=1)\n",
    "    df['Comment'] = df['Comment'].astype(str).apply(text_processing)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['Sentiment'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "    processed_comments = df[['Comment', 'Sentiment']].to_dict(orient='records')\n",
    "\n",
    "    return jsonify({'comments': processed_comments})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_analyzer.pkl', 'wb') as file:\n",
    "    pickle.dump(sentiments, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
